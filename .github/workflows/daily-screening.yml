name: Daily Stock Screening

on:
  # 每个交易日 18:00 北京时间 (UTC+8) = 10:00 UTC
  # BaoStock 日K线数据在 17:30 更新，留 30 分钟缓冲
  schedule:
    - cron: '0 10 * * 1-5'  # 周一到周五
  
  # 手动触发
  workflow_dispatch:
    inputs:
      date:
        description: '运行日期 (YYYY-MM-DD)'
        required: false
        type: string

env:
  PYTHON_VERSION: '3.12'
  WORKER_URL: 'https://ashare.aigc.it'
  WORKER_WRITE_TOKEN: 'test-token-local'

jobs:
  # Job 1: 运行测试
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'pipeline/requirements.txt'

      - name: Install dependencies
        working-directory: pipeline
        run: pip install -r requirements.txt

      - name: Run Python tests (Layer 1 + Layer 2)
        working-directory: pipeline
        run: |
          python -m pytest tests/unit/ tests/mock/ -v --tb=short

  # Job 2: 运行筛选
  screening:
    name: Run Screening
    runs-on: ubuntu-latest
    needs: test  # 测试通过后才运行
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'pipeline/requirements.txt'

      - name: Install dependencies
        working-directory: pipeline
        run: pip install -r requirements.txt

      # 缓存本地 SQLite 数据库
      - name: Cache SQLite database
        id: cache-db
        uses: actions/cache@v4
        with:
          path: pipeline/data/kline.db
          key: kline-db-${{ github.run_number }}
          restore-keys: |
            kline-db-

      # 如果缓存未恢复 db 文件，从 Release 下载初始数据
      - name: Download initial database from Release
        run: |
          if [ -f pipeline/data/kline.db ]; then
            echo "kline.db 已从缓存恢复 ($(ls -lh pipeline/data/kline.db | awk '{print $5}'))，跳过下载"
            exit 0
          fi
          mkdir -p pipeline/data
          # 尝试从最新 release 下载 kline.db
          DOWNLOAD_URL=$(curl -s https://api.github.com/repos/${{ github.repository }}/releases/latest | grep "browser_download_url.*kline.db" | cut -d '"' -f 4)
          if [ -n "$DOWNLOAD_URL" ]; then
            echo "从 Release 下载初始数据库..."
            curl -L -o pipeline/data/kline.db "$DOWNLOAD_URL"
            echo "下载完成: $(ls -lh pipeline/data/kline.db)"
          else
            echo "未找到 Release 中的 kline.db，将从头下载数据"
          fi

      - name: Run screening
        working-directory: pipeline
        run: |
          if [ -n "${{ github.event.inputs.date }}" ]; then
            python main.py --date "${{ github.event.inputs.date }}"
          else
            python main.py
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: screening-logs
          path: pipeline/data/
          retention-days: 7

